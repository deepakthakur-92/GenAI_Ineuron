{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lTr2zZQFKUBQ"
      },
      "outputs": [],
      "source": [
        "{\"messages\": [{\"role\": \"system\", \"content\": \"Marv is a factual chatbot that is also sarcastic.\"}, {\"role\": \"user\", \"content\": \"What's the capital of France?\"}, {\"role\": \"assistant\", \"content\": \"Paris, as if everyone doesn't know that already.\"}]}\n",
        "{\"messages\": [{\"role\": \"system\", \"content\": \"Marv is a factual chatbot that is also sarcastic.\"}, {\"role\": \"user\", \"content\": \"Who wrote 'Romeo and Juliet'?\"}, {\"role\": \"assistant\", \"content\": \"Oh, just some guy named William Shakespeare. Ever heard of him?\"}]}\n",
        "{\"messages\": [{\"role\": \"system\", \"content\": \"Marv is a factual chatbot that is also sarcastic.\"}, {\"role\": \"user\", \"content\": \"How far is the Moon from Earth?\"}, {\"role\": \"assistant\", \"content\": \"Around 384,400 kilometers. Give or take a few, like that really matters.\"}]}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"system\n",
        "user\n",
        "assistant\"\"\""
      ],
      "metadata": {
        "id": "uce_AtjsMVbP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K_CkJye0M_-u",
        "outputId": "0e448292-e3d1-41c6-a31c-2ccfa1c99e4b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-1.28.1-py3-none-any.whl (320 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m320.1/320.1 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.7.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.11.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.18.2)\n",
            "Installing collected packages: h11, httpcore, httpx, openai\n",
            "Successfully installed h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 openai-1.28.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "OPENAI_API_KEY=userdata.get('OPENAI_API_KEY')"
      ],
      "metadata": {
        "id": "xQBch3UWNN65"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "client = OpenAI(api_key=OPENAI_API_KEY)"
      ],
      "metadata": {
        "id": "fknWrNoxNAFU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "client.files.create(\n",
        "  file=open(\"mydata.jsonl\", \"rb\"),\n",
        "  purpose=\"fine-tune\"\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jFdwOZomMdTj",
        "outputId": "f1c587de-bf17-4daa-d017-51c75ed96a30"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FileObject(id='file-k64fIU50AuG6luv3FZrhu0CS', bytes=3138, created_at=1715491845, filename='mydata.jsonl', object='file', purpose='fine-tune', status='processed', status_details=None)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "files = client.files.list()"
      ],
      "metadata": {
        "id": "ms1leDCvQNMp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "files"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OWo_EQwBQN3k",
        "outputId": "2eb2365b-c806-44e9-acc1-a538a33d0c35"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SyncPage[FileObject](data=[FileObject(id='file-k64fIU50AuG6luv3FZrhu0CS', bytes=3138, created_at=1715491845, filename='mydata.jsonl', object='file', purpose='fine-tune', status='processed', status_details=None), FileObject(id='file-k10bwRjhXL488cvBee0c3TtW', bytes=783, created_at=1715490806, filename='mydata.jsonl', object='file', purpose='fine-tune', status='processed', status_details=None)], object='list', has_more=False)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for file in files:\n",
        "    if file.purpose == \"fine-tune\":\n",
        "        training_file_id = file.id\n",
        "        break"
      ],
      "metadata": {
        "id": "dBQIZbSaQSOs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_file_id"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "b60v0fyOQWDq",
        "outputId": "8c106978-ce82-495e-baff-84d30ca5b742"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'file-k64fIU50AuG6luv3FZrhu0CS'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "client.fine_tuning.jobs.create(\n",
        "    training_file=training_file_id,\n",
        "    model=\"gpt-3.5-turbo\"\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Kc6g0PNQMJg",
        "outputId": "94c1f392-fff0-4c3e-e0a0-51ce3a7bf67e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FineTuningJob(id='ftjob-QHPvVr4IMBVq0SIUOJK4byBz', created_at=1715491862, error=Error(code=None, message=None, param=None), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs='auto', batch_size='auto', learning_rate_multiplier='auto'), model='gpt-3.5-turbo-0125', object='fine_tuning.job', organization_id='org-YHkBwO20EkoAAteP1i4EYNpZ', result_files=[], seed=1062020798, status='validating_files', trained_tokens=None, training_file='file-k64fIU50AuG6luv3FZrhu0CS', validation_file=None, estimated_finish=None, integrations=[], user_provided_suffix=None)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "client.fine_tuning.jobs.list()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y5KAQKI9ObzU",
        "outputId": "9593c2f9-22e8-4075-d42c-22641eb21693"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SyncCursorPage[FineTuningJob](data=[FineTuningJob(id='ftjob-QHPvVr4IMBVq0SIUOJK4byBz', created_at=1715491862, error=Error(code=None, message=None, param=None), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs=8, batch_size=1, learning_rate_multiplier=2), model='gpt-3.5-turbo-0125', object='fine_tuning.job', organization_id='org-YHkBwO20EkoAAteP1i4EYNpZ', result_files=[], seed=1062020798, status='running', trained_tokens=None, training_file='file-k64fIU50AuG6luv3FZrhu0CS', validation_file=None, estimated_finish=None, integrations=[], user_provided_suffix=None), FineTuningJob(id='ftjob-ULIVUmwZt7Umeeis0CnvXLrT', created_at=1715491426, error=Error(code='invalid_n_examples', message='Training file has 3 example(s), but must have at least 10 examples', param='training_file'), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs='auto', batch_size='auto', learning_rate_multiplier='auto'), model='gpt-3.5-turbo-0125', object='fine_tuning.job', organization_id='org-YHkBwO20EkoAAteP1i4EYNpZ', result_files=[], seed=1945097503, status='failed', trained_tokens=None, training_file='file-k10bwRjhXL488cvBee0c3TtW', validation_file=None, estimated_finish=None, integrations=[], user_provided_suffix=None)], object='list', has_more=False)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "client.fine_tuning.jobs.retrieve(\"ftjob-QHPvVr4IMBVq0SIUOJK4byBz\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "59wgSPwgQwJJ",
        "outputId": "9c08ef80-ffd4-4c9b-f5f3-80f12c320874"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FineTuningJob(id='ftjob-QHPvVr4IMBVq0SIUOJK4byBz', created_at=1715491862, error=Error(code=None, message=None, param=None), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs=8, batch_size=1, learning_rate_multiplier=2), model='gpt-3.5-turbo-0125', object='fine_tuning.job', organization_id='org-YHkBwO20EkoAAteP1i4EYNpZ', result_files=[], seed=1062020798, status='running', trained_tokens=None, training_file='file-k64fIU50AuG6luv3FZrhu0CS', validation_file=None, estimated_finish=1715492131, integrations=[], user_provided_suffix=None)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "completion = client.chat.completions.create(\n",
        "  model=\"gpt-3.5-turbo-0125\",\n",
        "  messages=[\n",
        "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "    {\"role\": \"user\", \"content\": \"Hello!\"}\n",
        "  ]\n",
        ")\n",
        "print(completion.choices[0].message)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T6XklRETQ0q4",
        "outputId": "50f1c1c2-3bc8-46e2-86f4-2d54635c58fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ChatCompletionMessage(content='Hello! How can I assist you today?', role='assistant', function_call=None, tool_calls=None)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import csv\n",
        "\n",
        "\n",
        "# Replace 'your_path_here' with the path to the directory containing your file on Google Drive.\n",
        "# Make sure to keep '/content/drive/My Drive/' at the beginning.\n",
        "\n",
        "path_to_file = '/content/parenting_coach1.csv'\n",
        "output_path = '/content/parenting_coach1.jsonl'\n",
        "\n",
        "# Open the CSV file and read each line\n",
        "with open(path_to_file, 'r', newline='', encoding='utf-8') as csv_file:\n",
        "    csv_reader = csv.reader(csv_file)\n",
        "\n",
        "    with open(output_path, 'w', encoding='utf-8') as jsonl_file:\n",
        "        for row in csv_reader:\n",
        "            json_str = row[0]\n",
        "            json_obj = json.loads(json_str)\n",
        "            jsonl_file.write(json.dumps(json_obj) + '\\n')\n",
        "\n",
        "print(f\"Conversion complete. The JSONL file is saved as '{output_path}'.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n3G6lJKfS0nq",
        "outputId": "9ebd7555-779b-49e2-c405-d07dda7767eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Conversion complete. The JSONL file is saved as '/content/parenting_coach1.jsonl'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "client.files.create(\n",
        "  file=open(\"/content/parenting_coach1.jsonl\", \"rb\"),\n",
        "  purpose=\"fine-tune\"\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QIndH3TVTmrK",
        "outputId": "aeb01461-32a1-4fcf-bf5b-47d902a4efdb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FileObject(id='file-n8b1hgGcRpVnXxkKgzwynThB', bytes=12570, created_at=1715492298, filename='parenting_coach1.jsonl', object='file', purpose='fine-tune', status='processed', status_details=None)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "suffix_name = \"abc123\"\n",
        "response=client.fine_tuning.jobs.create(\n",
        "    training_file='file-n8b1hgGcRpVnXxkKgzwynThB',\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    suffix=suffix_name\n",
        ")\n"
      ],
      "metadata": {
        "id": "7h_q4d08TvGO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "job_id = response[\"id\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "id": "uPLdUz8LnygE",
        "outputId": "bb59d99e-70ef-4c0a-ad67-8d6c4b67450e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "'FineTuningJob' object is not subscriptable",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-f95ba2e2c5ca>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mjob_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"id\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: 'FineTuningJob' object is not subscriptable"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "54ILLZRMn1xx",
        "outputId": "6544cda1-6519-4e6d-ab46-778928fcf0a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FineTuningJob(id='ftjob-SgXfk2q90cvgzebEnzIsNPlq', created_at=1715497542, error=Error(code=None, message=None, param=None), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs='auto', batch_size='auto', learning_rate_multiplier='auto'), model='gpt-3.5-turbo-0125', object='fine_tuning.job', organization_id='org-YHkBwO20EkoAAteP1i4EYNpZ', result_files=[], seed=1482830994, status='validating_files', trained_tokens=None, training_file='file-n8b1hgGcRpVnXxkKgzwynThB', validation_file=None, estimated_finish=None, integrations=[], user_provided_suffix='abc123')"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "client.fine_tuning.jobs.list()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oPyUfgQsT4rH",
        "outputId": "fa51e6a9-c221-4ed6-a064-5f0d7f87457d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SyncCursorPage[FineTuningJob](data=[FineTuningJob(id='ftjob-SgXfk2q90cvgzebEnzIsNPlq', created_at=1715497542, error=Error(code=None, message=None, param=None), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs=3, batch_size=1, learning_rate_multiplier=2), model='gpt-3.5-turbo-0125', object='fine_tuning.job', organization_id='org-YHkBwO20EkoAAteP1i4EYNpZ', result_files=[], seed=1482830994, status='running', trained_tokens=None, training_file='file-n8b1hgGcRpVnXxkKgzwynThB', validation_file=None, estimated_finish=None, integrations=[], user_provided_suffix='abc123'), FineTuningJob(id='ftjob-Hw1m1YlzLPW8g5B9fHdKylij', created_at=1715492328, error=Error(code=None, message=None, param=None), fine_tuned_model='ft:gpt-3.5-turbo-0125:personal::9NwHXLDW', finished_at=1715492605, hyperparameters=Hyperparameters(n_epochs=3, batch_size=1, learning_rate_multiplier=2), model='gpt-3.5-turbo-0125', object='fine_tuning.job', organization_id='org-YHkBwO20EkoAAteP1i4EYNpZ', result_files=['file-nm0zADsethH70UJXOtcX4X0O'], seed=1839415463, status='succeeded', trained_tokens=6375, training_file='file-n8b1hgGcRpVnXxkKgzwynThB', validation_file=None, estimated_finish=None, integrations=[], user_provided_suffix=None), FineTuningJob(id='ftjob-QHPvVr4IMBVq0SIUOJK4byBz', created_at=1715491862, error=Error(code=None, message=None, param=None), fine_tuned_model='ft:gpt-3.5-turbo-0125:personal::9Nw9qxUu', finished_at=1715492129, hyperparameters=Hyperparameters(n_epochs=8, batch_size=1, learning_rate_multiplier=2), model='gpt-3.5-turbo-0125', object='fine_tuning.job', organization_id='org-YHkBwO20EkoAAteP1i4EYNpZ', result_files=['file-x8OKDcMRw8sjYpwL0hkYnISy'], seed=1062020798, status='succeeded', trained_tokens=4640, training_file='file-k64fIU50AuG6luv3FZrhu0CS', validation_file=None, estimated_finish=None, integrations=[], user_provided_suffix=None), FineTuningJob(id='ftjob-ULIVUmwZt7Umeeis0CnvXLrT', created_at=1715491426, error=Error(code='invalid_n_examples', message='Training file has 3 example(s), but must have at least 10 examples', param='training_file'), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs='auto', batch_size='auto', learning_rate_multiplier='auto'), model='gpt-3.5-turbo-0125', object='fine_tuning.job', organization_id='org-YHkBwO20EkoAAteP1i4EYNpZ', result_files=[], seed=1945097503, status='failed', trained_tokens=None, training_file='file-k10bwRjhXL488cvBee0c3TtW', validation_file=None, estimated_finish=None, integrations=[], user_provided_suffix=None)], object='list', has_more=False)"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Retrieve the state of a fine-tune\n",
        "response=client.fine_tuning.jobs.retrieve('ftjob-SgXfk2q90cvgzebEnzIsNPlq')"
      ],
      "metadata": {
        "id": "UBtbT0ajoQCk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response.fine_tuned_model"
      ],
      "metadata": {
        "id": "dszMwV0gpAmY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fine_tuned_model_id = response[\"fine_tuned_model\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "id": "1OlXW9LmofTv",
        "outputId": "295b6e2a-f262-4648-f3c1-fee0f86235e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "'FineTuningJob' object is not subscriptable",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-01fc5fcba5db>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfine_tuned_model_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"fine_tuned_model\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: 'FineTuningJob' object is not subscriptable"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#retrieve fine-tune model id\n",
        "response = openai.FineTuningJob.retrieve()\n",
        "fine_tuned_model_id = response[\"fine_tuned_model\"]"
      ],
      "metadata": {
        "id": "v25H9DuFoOJm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "completion = client.chat.completions.create(\n",
        "  model='gpt-3.5-turbo-0125',\n",
        "  messages=[\n",
        "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "    {\"role\": \"user\", \"content\": \"my son does not do the homework what should i do?\"}\n",
        "  ]\n",
        ")\n",
        "print(completion.choices[0].message)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z1sBpui9T9LP",
        "outputId": "dce8634f-1cdc-4f1b-80b0-81610eaf49b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ChatCompletionMessage(content=\"It's important to have a conversation with your son about why he is not doing his homework. Maybe there is an underlying issue that is bothering him or he is struggling with the material. Encourage him to talk to you about any challenges he may be facing so that you can offer support or help find a solution together. Setting up a routine or schedule for completing homework each day can also be helpful in establishing good study habits. Praise and reward your son when he does complete his homework to encourage positive behavior. If the issue persists, consider reaching out to his teacher or a school counselor for additional support.\", role='assistant', function_call=None, tool_calls=None)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip show openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9gawSzfSUd3Y",
        "outputId": "01e90f85-7204-4ae7-854f-0c3464766224"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name: openai\n",
            "Version: 1.28.1\n",
            "Summary: The official Python library for the openai API\n",
            "Home-page: \n",
            "Author: \n",
            "Author-email: OpenAI <support@openai.com>\n",
            "License: \n",
            "Location: /usr/local/lib/python3.10/dist-packages\n",
            "Requires: anyio, distro, httpx, pydantic, sniffio, tqdm, typing-extensions\n",
            "Required-by: \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "\n",
        "DEFAULT_SYSTEM_PROMPT = 'You are a teaching assistant for Machine Learning. You should help the user to answer his question.'\n",
        "\n",
        "def create_dataset(question, answer):\n",
        "    return {\n",
        "        \"messages\": [\n",
        "            {\"role\": \"system\", \"content\": DEFAULT_SYSTEM_PROMPT},\n",
        "            {\"role\": \"user\", \"content\": question},\n",
        "            {\"role\": \"assistant\", \"content\": answer},\n",
        "        ]\n",
        "    }\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    df = pd.read_csv(\"path/to/file.csv\", encoding='cp1252')\n",
        "    with open(\"train.jsonl\", \"w\") as f:\n",
        "        for _, row in df.iterrows():\n",
        "            example_str = json.dumps(create_dataset(row[\"Question\"], row[\"Answer\"]))\n",
        "            f.write(example_str + \"\\n\")\n"
      ],
      "metadata": {
        "id": "_4cf7Ja8VJlJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file = client.files.create(\n",
        "  file=open(\"/content/parenting_coach1.jsonl\", \"rb\"),\n",
        "  purpose=\"fine-tune\"\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "id": "vbZMJu6sp7z0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "job = client.fine_tuning.jobs.create(\n",
        "  training_file=file.id,\n",
        "  model=\"gpt-3.5-turbo\"\n",
        ")"
      ],
      "metadata": {
        "id": "wsWWgykGqFvw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file.id"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "bLSSWgmHqRsp",
        "outputId": "b5002dc1-2fc3-47ab-ecaf-9df0b9a2d0c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'file-hPF7JXVlGnnDq3R4102pZn0c'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "job.id"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "osA8GBCwqV5y",
        "outputId": "1b71876e-80a9-4e51-9831-109ce1e6813e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'ftjob-egHhpjeb0FCFPGIiH4ztjNLU'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "job = client.fine_tuning.jobs.retrieve(job.id)\n"
      ],
      "metadata": {
        "id": "875tcLc3qB-8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "job.fine_tuned_model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "aYTAdAIeqZpP",
        "outputId": "1725e65b-dec5-4bf9-b6bf-e49bdd347e60"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'ft:gpt-3.5-turbo-0125:personal::9NxoM6CV'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "completion = client.chat.completions.create(\n",
        "  model=job.fine_tuned_model,\n",
        "  messages=[\n",
        "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "    {\"role\": \"user\", \"content\": \"how to fix email issue\"}\n",
        "  ]\n",
        ")\n",
        "print(completion.choices[0].message)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q0gADIzlqNO5",
        "outputId": "823f74d1-e54f-4a17-f47d-a9c0978f224b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ChatCompletionMessage(content='Check all email settings, ensure internet connectivity, and consider contacting your email provider for further assistance.', role='assistant', function_call=None, tool_calls=None)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Pusng9suqelW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}